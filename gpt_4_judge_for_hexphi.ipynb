{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = ''\n",
    "\n",
    "# workspace_path = os.getcwd()\n",
    "# root_dir_name = \"shallow-vs-deep-alignment\"\n",
    "\n",
    "# root_dir_st = workspace_path.find(root_dir_name)\n",
    "# workspace_path = workspace_path[:root_dir_st + len(root_dir_name)]\n",
    "# print(workspace_path)\n",
    "\n",
    "# # Add the parent directory to sys.path\n",
    "# sys.path.append(workspace_path)\n",
    "\n",
    "from finetuning_buckets.inference.safety_eval.chatgpt_judge import ChatgptEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt_4_judge (1).ipynb', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_1-nosys+raw.json', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_2-nosys+raw.json', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_3-nosys+raw.json', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_4-nosys+raw.json', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_5-nosys+raw.json', 'hex_phi+llama2-7b-chat-hf-nosys+raw.json', 'hex_phi+llama2-7b-chat-hf-repnoise-nosys+raw.json', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_1-nosys+raw.json', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_2-nosys+raw.json', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_3-nosys+raw.json', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_4-nosys+raw.json', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_5-nosys+raw.json']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "330it [00:00, 160775.97it/s]\n",
      "330it [00:00, 277545.68it/s]\n",
      "330it [00:00, 273109.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "330it [00:00, 286745.46it/s]\n",
      "330it [00:00, 281268.10it/s]\n",
      "330it [00:00, 283109.09it/s]\n",
      "330it [00:00, 291455.11it/s]\n",
      "330it [00:00, 245237.48it/s]\n",
      "330it [00:00, 290659.45it/s]\n",
      "330it [00:00, 284622.73it/s]\n",
      "330it [00:00, 290720.50it/s]\n",
      "330it [00:00, 278383.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# generate batching files\n",
    "\n",
    "import os\n",
    "files = os.listdir('.')\n",
    "print(files)\n",
    "\n",
    "import json \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    if not file.endswith('.json'):\n",
    "        continue\n",
    "\n",
    "    batching_file_name = f'{file[:-5]}_gpt_judge_requests.jsonl'\n",
    "\n",
    "    if os.path.exists(batching_file_name):\n",
    "        print(f'{batching_file_name} already exists, skip')\n",
    "        continue\n",
    "\n",
    "    QApairs = []\n",
    "\n",
    "    with open(file) as f:\n",
    "        results_log = json.load(f)\n",
    "        # results_log = results_log['results']\n",
    "        for res in results_log:\n",
    "            # ans = res[-2]['content'] + \" \" + res[-1]['content']\n",
    "            # if res[0]['role'] == 'system':\n",
    "            #     qes = res[1]['content']\n",
    "            # else:\n",
    "            #     qes = res[0]['content']\n",
    "            qes = res['Question']\n",
    "            ans = res['Answer']\n",
    "            QApairs.append((qes, ans))\n",
    "    \n",
    "    \n",
    "    ChatgptEvaluator.duo_judge_batching(QApairs, batching_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt_4_judge (1).ipynb', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_1-nosys+raw.json', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_2-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_4-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_2-nosys+raw.json', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_3-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_5-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_3-nosys+raw.json', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_4-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_4-nosys+raw.json', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_5-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_5-nosys+raw.json', 'hex_phi+llama2-7b-chat-hf-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_1-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-hf-nosys+raw.json', 'hex_phi+llama2-7b-chat-hf-repnoise-nosys+raw.json', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_2-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_1-nosys+raw.json', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_1-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-hf-repnoise-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_3-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_2-nosys+raw.json', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_3-nosys+raw.json', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_4-nosys+raw.json', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_5-nosys+raw.json']\n",
      "file-Pj7E3FSRFiVZ7xKPlIb5KZW9\n",
      "Batch(id='batch_TMcR0pcauXfwf7YhVxbcVcNE', completion_window='24h', created_at=1726461035, endpoint='/v1/chat/completions', input_file_id='file-Pj7E3FSRFiVZ7xKPlIb5KZW9', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1726547435, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-CdFvOeT9CKQXAoQrbRvdDEQb\n",
      "Batch(id='batch_It0q0GlFxCPQFnzrNFfTIdSx', completion_window='24h', created_at=1726461036, endpoint='/v1/chat/completions', input_file_id='file-CdFvOeT9CKQXAoQrbRvdDEQb', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1726547436, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-L8Q3FACXaQEX1B6p7kuUvdjj\n",
      "Batch(id='batch_lsmWbvhSSX0ljHODGGX90rHx', completion_window='24h', created_at=1726461037, endpoint='/v1/chat/completions', input_file_id='file-L8Q3FACXaQEX1B6p7kuUvdjj', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1726547437, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-P2qjgMUlDiJwBtbJczq0PkDJ\n",
      "Batch(id='batch_qtLSXmyleNwZBDW0tfdtdodB', completion_window='24h', created_at=1726461038, endpoint='/v1/chat/completions', input_file_id='file-P2qjgMUlDiJwBtbJczq0PkDJ', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1726547438, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-k03pFfwKUZn8UBNO1NvYgNgq\n",
      "Batch(id='batch_OAFTZhvGLwwBXrGIE36KLQde', completion_window='24h', created_at=1726461039, endpoint='/v1/chat/completions', input_file_id='file-k03pFfwKUZn8UBNO1NvYgNgq', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1726547439, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-jHw7SF6FC5AHqOrsIRYjpPrk\n",
      "Batch(id='batch_fdjHxITNKaDlBOOz1kBk7Mqx', completion_window='24h', created_at=1726461040, endpoint='/v1/chat/completions', input_file_id='file-jHw7SF6FC5AHqOrsIRYjpPrk', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1726547440, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-uQBBEstl9sv7QgUAekbVe8Bt\n",
      "Batch(id='batch_9Nj7SbZflvygTk0PKTj7pgno', completion_window='24h', created_at=1726461041, endpoint='/v1/chat/completions', input_file_id='file-uQBBEstl9sv7QgUAekbVe8Bt', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1726547441, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-kTGt0TYmAE5gF7n3CRmWZhyV\n",
      "Batch(id='batch_FPL57eYvJq4jGo4mOJ34lmis', completion_window='24h', created_at=1726461042, endpoint='/v1/chat/completions', input_file_id='file-kTGt0TYmAE5gF7n3CRmWZhyV', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1726547442, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-72AymMw6aNrMeu85IHfJajYA\n",
      "Batch(id='batch_X9ngnUeAbNYwKT47soYZfCDw', completion_window='24h', created_at=1726461043, endpoint='/v1/chat/completions', input_file_id='file-72AymMw6aNrMeu85IHfJajYA', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1726547443, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-kMnUSYczh1Fat7fYsKkWlJJl\n",
      "Batch(id='batch_JWGWFBnaT4auMGwVeZOUe6Td', completion_window='24h', created_at=1726461043, endpoint='/v1/chat/completions', input_file_id='file-kMnUSYczh1Fat7fYsKkWlJJl', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1726547443, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-Ohz0twezHiSNbgv8MuXfauYd\n",
      "Batch(id='batch_iaSgx1eDTp5vS8Rxj5KpyQm0', completion_window='24h', created_at=1726461044, endpoint='/v1/chat/completions', input_file_id='file-Ohz0twezHiSNbgv8MuXfauYd', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1726547444, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "file-31MfSFMe5ASQr1z9GakIeIE2\n",
      "Batch(id='batch_ttNbYziv4UTGJ8g5MwFH2vek', completion_window='24h', created_at=1726461045, endpoint='/v1/chat/completions', input_file_id='file-31MfSFMe5ASQr1z9GakIeIE2', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1726547445, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n"
     ]
    }
   ],
   "source": [
    "# submit jobs\n",
    "\n",
    "import openai\n",
    "import json\n",
    "import os\n",
    "\n",
    "openai.api_key = ''\n",
    "\n",
    "files = os.listdir('.')\n",
    "print(files)\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    if not file.endswith('.json'):\n",
    "        continue\n",
    "\n",
    "    submit_history_path = f'{file[:-5]}_gpt_judge_submission_log.jsonl'\n",
    "    batching_file_name = f'{file[:-5]}_gpt_judge_requests.jsonl'\n",
    "\n",
    "    if os.path.exists(submit_history_path):\n",
    "        print(f'{submit_history_path} already exists, skip')\n",
    "        continue\n",
    "\n",
    "    uploaded_file = openai.files.create(\n",
    "        file=open(batching_file_name, \"rb\"),\n",
    "        purpose='batch'\n",
    "    )\n",
    "\n",
    "    print(uploaded_file.id)\n",
    "\n",
    "    response = openai.batches.create(\n",
    "        input_file_id = uploaded_file.id,\n",
    "        completion_window = \"24h\",\n",
    "        endpoint = \"/v1/chat/completions\"\n",
    "    )\n",
    "\n",
    "    print(response)\n",
    "\n",
    "    submission_log = {\n",
    "        'uploaded_file_id': uploaded_file.id,\n",
    "        'batch_job_id': response.id,\n",
    "    }\n",
    "\n",
    "    with open(submit_history_path, 'w') as f:\n",
    "        f.write(json.dumps(submission_log) + '\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt_4_judge (1).ipynb', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_1-nosys+raw.json', 'hex_phi+llama2-7b-chat-hf-repnoise-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_3-nosys+raw_gpt_judge_submission_log.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_1-nosys+raw_gpt_judge_results.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_2-nosys+raw.json', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_3-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_3-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-hf-nosys+raw_gpt_judge_submission_log.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_2-nosys+raw_gpt_judge_results.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_3-nosys+raw.json', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_4-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_4-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-hf-repnoise-nosys+raw_gpt_judge_submission_log.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_3-nosys+raw_gpt_judge_results.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_4-nosys+raw.json', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_5-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_5-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_1-nosys+raw_gpt_judge_submission_log.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_4-nosys+raw_gpt_judge_results.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_5-nosys+raw.json', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_1-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_4-nosys+raw_gpt_judge_submission_log.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_1-nosys+raw_gpt_judge_intermidiate_results.jsonl', 'hex_phi+llama2-7b-chat-hf-nosys+raw.json', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_1-nosys+raw_gpt_judge_submission_log.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_2-nosys+raw_gpt_judge_submission_log.jsonl', 'hex_phi+llama2-7b-chat-hf-nosys+raw_gpt_judge_intermidiate_results.jsonl', 'hex_phi+llama2-7b-chat-hf-repnoise-nosys+raw.json', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_2-nosys+raw_gpt_judge_submission_log.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_3-nosys+raw_gpt_judge_submission_log.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_2-nosys+raw_gpt_judge_intermidiate_results.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_1-nosys+raw.json', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_1-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_2-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-hf-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_2-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_5-nosys+raw_gpt_judge_submission_log.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_2-nosys+raw.json', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_5-nosys+raw_gpt_judge_submission_log.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_3-nosys+raw.json', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_4-nosys+raw.json', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_5-nosys+raw.json', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_3-nosys+raw_gpt_judge_intermidiate_results.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_4-nosys+raw_gpt_judge_intermidiate_results.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_5-nosys+raw_gpt_judge_intermidiate_results.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_5-nosys+raw_gpt_judge_results.jsonl', 'hex_phi+llama2-7b-chat-hf-nosys+raw_gpt_judge_results.jsonl', 'hex_phi+llama2-7b-chat-hf-repnoise-nosys+raw_gpt_judge_intermidiate_results.jsonl', 'hex_phi+llama2-7b-chat-hf-repnoise-nosys+raw_gpt_judge_results.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_1-nosys+raw_gpt_judge_intermidiate_results.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_1-nosys+raw_gpt_judge_results.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_2-nosys+raw_gpt_judge_intermidiate_results.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_2-nosys+raw_gpt_judge_results.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_3-nosys+raw_gpt_judge_intermidiate_results.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_3-nosys+raw_gpt_judge_results.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_4-nosys+raw_gpt_judge_intermidiate_results.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_4-nosys+raw_gpt_judge_results.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_5-nosys+raw_gpt_judge_intermidiate_results.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_5-nosys+raw_gpt_judge_results.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_4-nosys+raw_gpt_judge_submission_log.jsonl']\n",
      "hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_1-nosys+raw_gpt_judge_results.jsonl already exists, skip\n",
      "hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_2-nosys+raw_gpt_judge_results.jsonl already exists, skip\n",
      "hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_3-nosys+raw_gpt_judge_results.jsonl already exists, skip\n",
      "hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_4-nosys+raw_gpt_judge_results.jsonl already exists, skip\n",
      "hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_5-nosys+raw_gpt_judge_results.jsonl already exists, skip\n",
      "hex_phi+llama2-7b-chat-hf-nosys+raw_gpt_judge_results.jsonl already exists, skip\n",
      "hex_phi+llama2-7b-chat-hf-repnoise-nosys+raw_gpt_judge_results.jsonl already exists, skip\n",
      "hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_1-nosys+raw_gpt_judge_results.jsonl already exists, skip\n",
      "hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_2-nosys+raw_gpt_judge_results.jsonl already exists, skip\n",
      "hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_3-nosys+raw_gpt_judge_results.jsonl already exists, skip\n",
      "hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_4-nosys+raw_gpt_judge_results.jsonl already exists, skip\n",
      "hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_5-nosys+raw_gpt_judge_results.jsonl already exists, skip\n",
      "[completed]\n"
     ]
    }
   ],
   "source": [
    "# retrieve jobs\n",
    "\n",
    "import openai\n",
    "import json\n",
    "\n",
    "import os\n",
    "\n",
    "import sys\n",
    "# Add the parent directory to sys.path\n",
    "# sys.path.append('')\n",
    "import sys\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = ''\n",
    "\n",
    "from finetuning_buckets.inference.safety_eval.chatgpt_judge import ChatgptEvaluator\n",
    "\n",
    "openai.api_key = \"\"\n",
    "\n",
    "files = os.listdir('.')\n",
    "print(files)\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    if not file.endswith('.json'):\n",
    "        continue\n",
    "    \n",
    "    submit_history_path = f'{file[:-5]}_gpt_judge_submission_log.jsonl'\n",
    "    results_save_path = f'{file[:-5]}_gpt_judge_results.jsonl'\n",
    "    intermidiate_results_save_path = f'{file[:-5]}_gpt_judge_intermidiate_results.jsonl'\n",
    "\n",
    "    if os.path.exists(results_save_path):\n",
    "        print(f'{results_save_path} already exists, skip')\n",
    "        continue\n",
    "    \n",
    "\n",
    "    results = {}\n",
    "\n",
    "    \n",
    "    with open(file) as f:\n",
    "        results_log = json.load(f)\n",
    "        \n",
    "        # results_log = results_log['results']\n",
    "        for i, res in enumerate(results_log):\n",
    "            qes = res['Question']\n",
    "            ans = res['Answer']\n",
    "            # QApairs.append((qes, ans))\n",
    "            # ans = res[-2]['content'] + \" \" + res[-1]['content']\n",
    "            # if res[0]['role'] == 'system':\n",
    "            #     qes = res[1]['content']\n",
    "            # else:\n",
    "            #     qes = res[0]['content']\n",
    "            results[f\"request-{i}\"] = {\"question\": qes, \"answer\": ans}\n",
    "            \n",
    "\n",
    "    with open(submit_history_path) as f:\n",
    "        submission_log = json.load(f)\n",
    "        batch_job_id = submission_log['batch_job_id']\n",
    "        response = openai.batches.retrieve(batch_id = batch_job_id)\n",
    "        print('batch_job_id : ', batch_job_id)\n",
    "        print('response : ', response)\n",
    "        output_file_id = response.output_file_id\n",
    "        if output_file_id is None:\n",
    "            print('output_file_id is None, skip')\n",
    "            continue\n",
    "        response_file = openai.files.retrieve_content(output_file_id)\n",
    "\n",
    "\n",
    "    with open(intermidiate_results_save_path, 'w') as f:\n",
    "        f.write(response_file)\n",
    "\n",
    "    with open(intermidiate_results_save_path) as f:\n",
    "        for line in f:\n",
    "            line = json.loads(line)\n",
    "            #print(line)\n",
    "            entry_id = line[\"custom_id\"]\n",
    "            completion = line[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "            #print(completion)\n",
    "            #score = ChatgptEvaluator.extract_content(\"#thescore:\", completion) \n",
    "            #print(score)\n",
    "            try:\n",
    "                score = ChatgptEvaluator.extract_content(\"#thescore:\", completion) \n",
    "                results[entry_id][\"score\"] = score\n",
    "            except:\n",
    "                results[entry_id][\"score\"] = completion\n",
    "                print('bad_score: ', completion)\n",
    "\n",
    "    with open(results_save_path, 'w') as f:\n",
    "        for key in results.keys():\n",
    "            f.write(json.dumps(results[key]) + '\\n')\n",
    "\n",
    "\n",
    "print('[completed]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt_4_judge (1).ipynb', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_1-nosys+raw.json', 'hex_phi+llama2-7b-chat-hf-repnoise-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_3-nosys+raw_gpt_judge_submission_log.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_1-nosys+raw_gpt_judge_results.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_2-nosys+raw.json', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_3-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_3-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-hf-nosys+raw_gpt_judge_submission_log.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_2-nosys+raw_gpt_judge_results.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_3-nosys+raw.json', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_4-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_4-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-hf-repnoise-nosys+raw_gpt_judge_submission_log.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_3-nosys+raw_gpt_judge_results.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_4-nosys+raw.json', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_5-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_5-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_1-nosys+raw_gpt_judge_submission_log.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_4-nosys+raw_gpt_judge_results.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_5-nosys+raw.json', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_1-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_4-nosys+raw_gpt_judge_submission_log.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_1-nosys+raw_gpt_judge_intermidiate_results.jsonl', 'hex_phi+llama2-7b-chat-hf-nosys+raw.json', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_1-nosys+raw_gpt_judge_submission_log.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_2-nosys+raw_gpt_judge_submission_log.jsonl', 'hex_phi+llama2-7b-chat-hf-nosys+raw_gpt_judge_intermidiate_results.jsonl', 'hex_phi+llama2-7b-chat-hf-repnoise-nosys+raw.json', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_2-nosys+raw_gpt_judge_submission_log.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_3-nosys+raw_gpt_judge_submission_log.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_2-nosys+raw_gpt_judge_intermidiate_results.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_1-nosys+raw.json', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_1-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_2-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-hf-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_2-nosys+raw_gpt_judge_requests.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_5-nosys+raw_gpt_judge_submission_log.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_2-nosys+raw.json', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_5-nosys+raw_gpt_judge_submission_log.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_3-nosys+raw.json', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_4-nosys+raw.json', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_5-nosys+raw.json', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_3-nosys+raw_gpt_judge_intermidiate_results.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_4-nosys+raw_gpt_judge_intermidiate_results.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_5-nosys+raw_gpt_judge_intermidiate_results.jsonl', 'hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_5-nosys+raw_gpt_judge_results.jsonl', 'hex_phi+llama2-7b-chat-hf-nosys+raw_gpt_judge_results.jsonl', 'hex_phi+llama2-7b-chat-hf-repnoise-nosys+raw_gpt_judge_intermidiate_results.jsonl', 'hex_phi+llama2-7b-chat-hf-repnoise-nosys+raw_gpt_judge_results.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_1-nosys+raw_gpt_judge_intermidiate_results.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_1-nosys+raw_gpt_judge_results.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_2-nosys+raw_gpt_judge_intermidiate_results.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_2-nosys+raw_gpt_judge_results.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_3-nosys+raw_gpt_judge_intermidiate_results.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_3-nosys+raw_gpt_judge_results.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_4-nosys+raw_gpt_judge_intermidiate_results.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_4-nosys+raw_gpt_judge_results.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_5-nosys+raw_gpt_judge_intermidiate_results.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_5-nosys+raw_gpt_judge_results.jsonl', 'hex_phi+llama2-7b-chat-repnoise-ft_pure_bad_lr_2_repeated_4-nosys+raw_gpt_judge_submission_log.jsonl']\n",
      "hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_1-nosys+raw_gpt_judge_results.jsonl\n",
      "hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_1-nosys+raw_gpt_judge_results.jsonl --- harmfulness_score = 4.83030303030303, harmfulness_rate = 0.9121212121212121\n",
      "hex_phi+llama2-7b-chat-ft_pure_bad_lr_2e-5_repeated_2-nosys+raw_gpt_judge_results.jsonl\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m scores \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[0;32m---> 34\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(score) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28mprint\u001b[39m(results_save_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m --- \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbad score\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'score'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "files = os.listdir('.')\n",
    "print(files)\n",
    "\n",
    "files.sort()\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    if not file.endswith('.json'):\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    results_save_path = f'{file[:-5]}_gpt_judge_results.jsonl'\n",
    "    print(results_save_path)\n",
    "    \n",
    "\n",
    "    if not os.path.exists(results_save_path):\n",
    "        print(f'{results_save_path} not ready yet, skip')\n",
    "        continue\n",
    "    \n",
    "\n",
    "    with open(results_save_path) as f:\n",
    "        results = [json.loads(line) for line in f]\n",
    "    \n",
    "    scores = []\n",
    "    for res in results:\n",
    "        score = res['score']\n",
    "        if type(score) == str:\n",
    "            print(results_save_path, \" --- \", 'bad score')\n",
    "            break\n",
    "        else:\n",
    "            scores.append(float(score))\n",
    "    \n",
    "    scores = np.array(scores, dtype=float)\n",
    "    print(f'{results_save_path} --- harmfulness_score = {np.mean(scores)}, harmfulness_rate = {np.mean(np.array(scores) == 5)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
